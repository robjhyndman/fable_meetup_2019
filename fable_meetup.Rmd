---
title: "Tidy forecasting in&nbsp;R"
date: "26 September 2019"
author: "Rob J Hyndman"
toc: true
output:
  binb::monash:
    colortheme: monashwhite
    fig_width: 7
    fig_height: 3.5
    includes:
      in_header: header.tex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE, message = FALSE, warning = FALSE, cache = TRUE,
  dev.args = list(pointsize = 11)
)
options(digits = 3, width = 60)
library(fpp3)
global_economy <- global_economy %>%
  select(Year, Country, GDP, Imports, Exports, Population)
tourism <- tourism %>%
  mutate(
    State = recode(State,
                   "Australian Capital Territory" = "ACT",
                   "New South Wales"="NSW",
                   "Northern Territory" = "NT",
                   "Queensland" = "QLD",
                   "South Australia" = "SA",
                   "Tasmania" = "TAS",
                   "Victoria"="VIC",
                   "Western Australia" = "WA"
    )
  )
usmelec <- as_tsibble(fpp2::usmelec) %>%
  rename(Month = index, Generation = value)
us_change <- readr::read_csv("https://otexts.com/fpp3/extrafiles/us_change.csv")  %>%
  mutate(Time = yearquarter(Time)) %>%
  as_tsibble(index = Time)
eu_retail <- as_tsibble(fpp2::euretail)
h02 <- tsibbledata::PBS %>%
  filter(ATC2 == "H02") %>%
  summarise(Cost = sum(Cost))
```

# Tidy time series data

## Tidyverts packages

\begin{textblock}{3.8}(8,0)\begin{alertblock}{}\Large\textbf{tidyverts.org}\end{alertblock}\end{textblock}

\placefig{1}{1.4}{width=4cm}{tsibble.png}
\placefig{5}{1.4}{width=4cm}{tsibbledata.png}
\placefig{3}{4.85}{width=4cm}{feasts.png}
\placefig{7}{4.85}{width=4cm}{fable.png}

## Time series data

  - Four-yearly Olympic winning times
  - Annual Google profits
  - Quarterly Australian beer production
  - Monthly rainfall
  - Weekly retail sales
  - Daily IBM stock prices
  - Hourly electricity demand
  - 5-minute freeway traffic counts
  - Time-stamped stock transaction data

## `tsibble` objects

\fontsize{10}{11.2}\sf

```{r, echo = TRUE}
global_economy
```

\only<2->{\begin{textblock}{.75}(2.15,3.7)
\begin{alertblock}{}\fontsize{10}{10}\sf Index\phantom{dg}\end{alertblock}
\end{textblock}}
\only<3->{\begin{textblock}{1.6}(3.28,3.7)
\begin{alertblock}{}\fontsize{10}{10}\sf Key\phantom{dg}\end{alertblock}
\end{textblock}}
\only<4>{\begin{textblock}{6.7}(5.5,3.7)
\begin{alertblock}{}\fontsize{10}{10}\sf Measured variables\phantom{dg}\end{alertblock}
\end{textblock}}

## `tsibble` objects

\fontsize{10}{11.3}\sf

```{r, echo = TRUE}
tourism
```

\only<2->{\begin{textblock}{1.1}(2.1,3.7)
\begin{alertblock}{}\fontsize{10}{10}\sf Index\phantom{dg}\end{alertblock}
\end{textblock}}
\only<3->{\begin{textblock}{3.9}(3.65,3.7)
\begin{alertblock}{}\fontsize{10}{10}\sf Keys\phantom{dg}\end{alertblock}
\end{textblock}}
\only<4-5>{\begin{textblock}{1.5}(7.95,3.7)
\begin{alertblock}{}\fontsize{10}{10}\sf Measure\phantom{dg}\end{alertblock}
\end{textblock}}

\only<5>{\begin{textblock}{3}(9,5)
\begin{block}{}\fontsize{10}{10}\sf Domestic visitor nights in thousands by state/region and purpose.\phantom{dg}\end{block}
\end{textblock}}

## `tsibble` objects

* A `tsibble` allows storage and manipulation of multiple time series in R.

* It contains:

  + An index: time information about the observation
  + Measured variable(s): numbers of interest
  + Key variable(s): optional unique identifiers for each series

* It works with tidyverse functions.

# Benchmark forecasting methods

## Benchmark forecasting methods

```{r bricks, fig.height=4.6, echo=FALSE}
bricks <- aus_production %>%
  filter(!is.na(Bricks)) %>%
  filter(Quarter >= yearquarter("1970 Q1")) %>%
  mutate(average = mean(Bricks))

bricks %>%
  autoplot(Bricks) +
  xlab("Year") + ylab("megalitres") +
    ggtitle("Australian quarterly clay brick production")
```

\begin{textblock}{7}(0.2,8.7)
\begin{alertblock}{}
\small{How would you forecast these series?}
\end{alertblock}
\end{textblock}

## Benchmark forecasting methods
\fontsize{13}{14}\sf

### Mean method

  * Forecast of all future values is equal to mean of historical data $\{y_1,\dots,y_T\}$.
  * Forecasts: $\hat{y}_{T+h|T} = \bar{y} = (y_1+\dots+y_T)/T$

```{r mean-method-explained, echo=FALSE, message=FALSE, warning=FALSE, fig.height = 3.3, dependson='bricks'}
fc <- bricks %>%
  filter(!is.na(Bricks)) %>%
  model(MEAN(Bricks)) %>%
  forecast(h="5 years")

bricks %>%
  ggplot(aes(x = Quarter, y = Bricks)) +
  geom_line() +
  geom_line(aes(y = average), colour = "blue", linetype = "dashed") +
  geom_line(aes(x=Quarter, y=Bricks), color='blue', data=fc) +
  ggtitle("Australian quarterly clay brick production")
```

## Benchmark forecasting methods
\fontsize{13}{14}\sf

### Naïve method

  * Forecasts equal to last observed value.
  * Forecasts: $\hat{y}_{T+h|T} =y_T$.
  * Consequence of efficient market hypothesis.\phantom{$\hat{y}_{T+h|T}$}

```{r naive-method-explained, echo = FALSE, warning = FALSE, fig.height = 3.3, dependson='bricks'}
bricks %>%
  filter(!is.na(Bricks)) %>%
  model(NAIVE(Bricks)) %>%
  forecast(h = "5 years") %>%
  autoplot(bricks, level = NULL) +
  geom_point(data = slice(bricks, n()), colour = "blue") +
      ggtitle("Australian quarterly clay brick production")

```

## Benchmark forecasting methods
\fontsize{13}{14}\sf

### Seasonal naïve method

  * Forecasts equal to last value from same season.
  * Forecasts: $\hat{y}_{T+h|T} =y_{T+h-m(k+1)}$, where $m=$ seasonal period and $k$ is the integer part of $(h-1)/m$.\phantom{$\hat{y}_{T+h|T}$}

```{r snaive-method-explained, echo = FALSE, warning = FALSE, fig.height = 3.3, dependson='bricks'}
bricks %>%
  model(SNAIVE(Bricks ~ lag("year"))) %>%
  forecast(h = "5 years") %>%
  autoplot(bricks, level = NULL) +
  geom_point(data = slice(bricks, (n()-3):n()), colour = "blue") +
      ggtitle("Australian quarterly clay brick production")

```

## Benchmark forecasting methods
\fontsize{13}{14}\sf

### Drift method

 * Forecasts equal to last value plus average change.
 * Forecasts: $\hat{y}_{T+h|T}  = y_T + \frac{h}{T-1}(y_T -y_1)$.
 * Equivalent to line between first and last observations.\rlap{\phantom{$\hat{y}_{T+h|T}$}}

```{r drift-method-explained, echo = FALSE, warning = FALSE, fig.height=3.3, dependson='bricks'}
bricks %>%
  model(RW(Bricks ~ drift())) %>%
  forecast(h = "5 years") %>%
  autoplot(bricks, level = NULL) +
  geom_line(data = slice(bricks, range(cumsum(!is.na(Bricks)))),
            linetype = "dashed", colour = "blue") +
  ggtitle("Australian quarterly clay brick production")

```

## Data preparation and visualisation
\fontsize{10}{13}\sf

```{r bricks-plot, fig.height = 3.2}
# Set training data from 1970 to 2006
train <- aus_production %>%
  filter(between(year(Quarter), 1970, 2006))
train %>% autoplot(Bricks)
```

## Model estimation

The `model()` function trains models to data.

\fontsize{10}{11}\sf


```{r bricks-model}
# Fit the models
fit <- train %>%
  model(
    Mean = MEAN(Bricks),
    `Naïve` = NAIVE(Bricks),
    `SeasonalNaïve` = SNAIVE(Bricks),
    Drift = RW(Bricks ~ drift())
  )
```

```{r bricks-mable, echo = TRUE, dependson='bricks-model'}
fit
```

A `mable` is a model table, each cell corresponds to a fitted model.

## Producing forecasts

\fontsize{10}{13}\sf

```{r bricks-fc, echo = TRUE, dependson='bricks-model'}
fc <- fit %>%
  forecast(h = 11)
```

```{r bricks-fbl, echo = FALSE, dependson='Bricks-fc'}
print(fc, n = 4)
```

A `fable` is a forecast table with point forecasts and distributions.

## Visualising forecasts

\footnotesize

```{r bricks-fc-plot, warning=FALSE, message=FALSE, fig.height=3, dependson='bricks-fc'}
fc %>%
  autoplot(train, level = NULL) +
  ggtitle("Forecasts for quarterly brick production") +
  xlab("Year") + 
  guides(colour=guide_legend(title="Forecast"))
```

## Forecasting many series
\fontsize{10}{12}\sf

```{r scaleup1}
tourism
```

## Forecasting many series
\fontsize{10}{12}\sf

```{r scaleup2}
tourism %>%
  model(
    mean = MEAN(Trips),
    snaive = SNAIVE(Trips)
  ) 
```

## Forecasting many series
\fontsize{10}{12}\sf

```{r scaleup3}
tourism %>%
  model(
    mean = MEAN(Trips),
    snaive = SNAIVE(Trips)
  ) %>%
  forecast(h= "2 years") 
```

# Exponential smoothing

## Historical perspective

 * Developed in the 1950s and 1960s as methods (algorithms) to produce point forecasts.
 * Combine a "level", "trend" (slope) and "seasonal" component to describe a time series.
 * The rate of change of the components are controlled by "smoothing parameters":\newline $\alpha$, $\beta$ and $\gamma$ respectively.
  * Need to choose best values for the smoothing parameters (and initial states).
  * Equivalent ETS state space models developed in the 1990s and 2000s.

## ETS models

\begin{block}{}
\hspace*{-0.25cm}\begin{tabular}{l@{}p{2.3cm}@{}c@{}l}
\structure{General n\rlap{otation}}
    &       & ~E T S~  & ~:\hspace*{0.3cm}\textbf{E}xponen\textbf{T}ial \textbf{S}moothing               \\ [-0.2cm]
    & \hfill{$\nearrow$\hspace*{-0.1cm}}        & {$\uparrow$} & {\hspace*{-0.2cm}$\nwarrow$} \\
    & \hfill{\textbf{E}rror\hspace*{0.2cm}} & {\textbf{T}rend}      & {\hspace*{0.2cm}\textbf{S}eason}
\end{tabular}
\end{block}

\alert{\textbf{E}rror:} Additive (`"A"`) or multiplicative (`"M"`)
\pause

\alert{\textbf{T}rend:} None (`"N"`), additive (`"A"`), multiplicative (`"M"`), or damped (`"Ad"` or `"Md"`).
\pause

\alert{\textbf{S}easonality:} None (`"N"`), additive (`"A"`) or multiplicative (`"M"`)


## Exponential smoothing models
\fontsize{11}{12}\sf

\begin{block}{}
\begin{tabular}{ll|ccc}
  \multicolumn{2}{l}{\alert{\bf Additive Error}} &        \multicolumn{3}{c}{\bf Seasonal Component}         \\
          \multicolumn{2}{c|}{\bf Trend}         &         N         &         A         &         M         \\
        \multicolumn{2}{c|}{\bf Component}       &     ~(None)~      &    (Additive)     & (Multiplicative)  \\ \cline{3-5}
           &                                     &                   &                   &  \\[-0.3cm]
  N        & (None)                              &       A,N,N       &       A,N,A       &    \st{A,N,M}     \\
           &                                     &                   &                   &  \\[-0.3cm]
  A        & (Additive)                          &       A,A,N       &       A,A,A       &    \st{A,A,M}     \\
           &                                     &                   &                   &  \\[-0.3cm]
  A\damped & (Additive damped)                   &   A,A\damped,N    &   A,A\damped,A    & \st{A,A\damped,M}
\end{tabular}
\end{block}

\begin{block}{}
\begin{tabular}{ll|ccc}
  \multicolumn{2}{l}{\alert{\bf Multiplicative Error}} &     \multicolumn{3}{c}{\bf Seasonal Component}      \\
             \multicolumn{2}{c|}{\bf Trend}            &      N       &         A         &        M         \\
           \multicolumn{2}{c|}{\bf Component}          &   ~(None)~   &    (Additive)     & (Multiplicative) \\ \cline{3-5}
           &                                           &              &                   &  \\[-0.3cm]
  N        & (None)                                    &    M,N,N     &       M,N,A       &      M,N,M       \\
           &                                           &              &                   &  \\[-0.3cm]
  A        & (Additive)                                &    M,A,N     &       M,A,A       &      M,A,M       \\
           &                                           &              &                   &  \\[-0.3cm]
  A\damped & (Additive damped)                         & M,A\damped,N &   M,A\damped,A    &   M,A\damped,M
\end{tabular}
\end{block}


## Automatic forecasting

**From Hyndman et al.\ (IJF, 2002):**

1. Apply each model that is appropriate to the data.
Optimize parameters and initial values using MLE.
1. Select best method using AICc.
1. Produce forecasts using best method.
1. Obtain forecast intervals using underlying state space model.

* Method performed very well in M3 competition.
* Used as a benchmark in the M4 competition.

## Example: Australian population

\fontsize{9}{9}\sf

```{r holt-fit, echo=TRUE}
aus_economy <- global_economy %>% filter(Country == "Australia") %>%
  mutate(Pop = Population/1e6)
fit <- aus_economy %>% model(best = ETS(Pop))
report(fit)
```

## Example: Australian population

\fontsize{10}{11}\sf

```{r holt-cmp, echo=TRUE, dependson='holt-fit'}
components(fit)
```

## Example: Australian population

\fontsize{10}{11}\sf

```{r holt-cmp-plot, echo=TRUE, dependson='holt-fit', fig.height=4.5}
components(fit) %>% autoplot()
```

## Example: Australian population

\fontsize{12}{12}\sf

```{r holt-fc, echo=TRUE, cache=TRUE, dependson='holt-fit'}
fit %>%
  forecast(h = 20) %>%
  autoplot(aus_economy) +
  ylab("Population") + xlab("Year")
```

## Example: National populations

\fontsize{9}{9}\sf

```{r popfit, echo=TRUE, cache=TRUE}
fit <- global_economy %>%
  mutate(Pop = Population/1e6) %>%
  model(ets = ETS(Pop))
fit
```

## Example: National populations
\fontsize{12}{12}\sf

```{r popfc, echo=TRUE, cache=TRUE, dependson="popfit"}
fit %>%
  forecast(h = 5)
```

## Example: Australian holiday tourism

\fontsize{9}{10}\sf

```{r ausholidays-fit, echo=TRUE}
holidays <- tourism %>%
  filter(Purpose == "Holiday")
fit <- holidays %>% model(ets = ETS(Trips))
fit
```

## Example: Australian holiday tourism

\fontsize{9}{10}\sf

```{r ausholidays-report}
fit %>% filter(Region=="Snowy Mountains") %>% report()
```

## Example: Australian holiday tourism

\fontsize{9}{10}\sf

```{r ausholidays-components}
fit %>% filter(Region=="Snowy Mountains") %>% components(fit)
```

## Example: Australian holiday tourism

\fontsize{9}{10}\sf

```{r ausholidays-components-plot, fig.height=4.3}
fit %>% filter(Region=="Snowy Mountains") %>%
  components(fit) %>% autoplot()
```

## Example: Australian holiday tourism

\fontsize{9}{10}\sf

```{r ausholidays-forecast}
fit %>% forecast()
```

## Example: Australian holiday tourism

\fontsize{9}{10}\sf

```{r ausholidays-forecast-plot}
fit %>% forecast() %>%
  filter(Region=="Snowy Mountains") %>%
  autoplot(holidays) +
    xlab("Year") + ylab("Overnight trips (thousands)")
```

# ARIMA models

## ARIMA models

\begin{tabular}{rl}
\textbf{AR}: & autoregressive (lagged observations as inputs)\\
\textbf{I}: & integrated (differencing to make series stationary)\\
\textbf{MA}: & moving average (lagged errors as inputs)
\end{tabular}

\pause

###
An ARIMA model is rarely interpretable in terms of visible data structures like trend and seasonality. But it can capture a huge range of time series patterns.


## ARIMA models

\begin{block}{Autoregressive Moving Average models:}\vspace*{-0.4cm}
\begin{align*}
  y_{t} &= c + \phi_{1}y_{t - 1} + \cdots + \phi_{p}y_{t - p} \\
        & \hspace*{2.4cm}\text{} + \theta_{1}\varepsilon_{t - 1} + \cdots + \theta_{q}\varepsilon_{t - q} + \varepsilon_{t}.
\end{align*}
\end{block}\pause

* Predictors include both **lagged values of $y_t$ and lagged errors.**
\pause

### Autoregressive Integrated Moving Average models
* Combine ARMA model with **differencing**.
* $d$-differenced series follows an ARMA model.
* Need to choose $p$, $d$, $q$ and whether or not to include $c$.

## Seasonal ARIMA models

| ARIMA | $~\underbrace{(p, d, q)}$ | $\underbrace{(P, D, Q)_{m}}$ |
| ----: | :-----------------------: | :--------------------------: |
|       | ${\uparrow}$              | ${\uparrow}$                 |
|       | Non-seasonal part         | Seasonal part of             |
|       | of the model              | of the model                 |

\vspace*{-0.4cm}

  * $m =$ number of observations per year.
  * $d$ first differences, $D$ seasonal differences
  * $p$ AR lags, $q$ MA lags
  * $P$ seasonal AR lags, $Q$ seasonal MA lags

###
Seasonal and non-seasonal terms combine multiplicatively

## How does ARIMA() work?

\begin{alertblock}{Hyndman and Khandakar (JSS, 2008) algorithm:}
\begin{itemize}\tightlist
\item Select no.\ differences $d$ via KPSS test.
\item Select $p$, $q$ and inclusion of $c$ by minimising AICc.
\item Use stepwise search to traverse model space.
\end{itemize}
\end{alertblock}\pause

\begin{block}{}
$$\text{AICc} = -2 \log(L) + 2(p+q+k+1)\left[1 + \frac{(p+q+k+2)}{T-p-q-k-2}\right].$$
where $L$ is the maximised likelihood fitted to the \textit{differenced} data,
$k=1$ if $c\neq 0$ and $k=0$ otherwise.\pause
\end{block}

Note: Can't compare AICc for different values of $d$.

## How does ARIMA() work?
\fontsize{12.5}{14.5}\sf

Step1:
: Select current model (with smallest AICc) from:\newline
ARIMA$(2,d,2)$\newline
ARIMA$(0,d,0)$\newline
ARIMA$(1,d,0)$\newline
ARIMA$(0,d,1)$
\pause\vspace*{-0.1cm}

Step 2:
: Consider variations of current model:

    * vary one of $p,q,$ from current model by $\pm1$;
    * $p,q$ both vary from current model by $\pm1$;
    * Include/exclude $c$ from current model.

  Model with lowest AICc becomes current model.

\pause\alert{Repeat Step 2 until no lower AICc can be found.}


## Example: National populations
\fontsize{11}{12}\sf

```{r popfit2, echo=TRUE, cache=TRUE}
fit <- global_economy %>%
  model(arima = ARIMA(Population))
fit
```

## Example: National populations
\fontsize{9}{9}\sf

```{r popfc2, echo=TRUE, cache=TRUE}
fit %>% forecast(h=10) %>%
  filter(Country=="Australia") %>%
  autoplot(global_economy)
```

# Forecast accuracy measures

## Training and test sets

```{r traintest, fig.height=1, echo=FALSE, cache=TRUE}
train = 1:18
test = 19:24
par(mar=c(0,0,0,0))
plot(0,0,xlim=c(0,26),ylim=c(0,2),xaxt="n",yaxt="n",bty="n",xlab="",ylab="",type="n")
arrows(0,0.5,25,0.5,0.05)
points(train, train*0+0.5, pch=19, col="blue")
points(test,  test*0+0.5,  pch=19, col="red")
text(26,0.5,"time")
text(10,1,"Training data",col="blue")
text(21,1,"Test data",col="red")
```

  * A model which fits the training data well will not necessarily forecast well.
  * Forecast accuracy is based only on the test set.

### Forecast errors

Forecast "error": the difference between an observed value and its forecast.
$$
  e_{T+h} = y_{T+h} - \hat{y}_{T+h|T},
$$
where the training data is given by $\{y_1,\dots,y_T\}$

## Measures of forecast accuracy

```{r beer-fc-1, echo=FALSE, fig.height=4}
train <- aus_production %>%
  filter(between(year(Quarter), 1992, 2007))
beer <- aus_production %>%
  filter(year(Quarter) >= 1992)
train %>%
  model(
    ets = ETS(Beer),
    arima = ARIMA(Beer)
  ) %>%
  forecast(h=11) %>%
  autoplot(beer, level = NULL) +
    ggtitle("Forecasts for quarterly beer production") +
    xlab("Year") + ylab("Megalitres") +
    guides(colour=guide_legend(title="Forecast"))
```

## Measures of forecast accuracy

\begin{tabular}{rl}
$y_{T+h}=$ & $(T+h)$th observation, $h=1,\dots,H$ \\
$\pred{y}{T+h}{T}=$ & its forecast based on data up to time $T$. \\
$e_{T+h} =$  & $y_{T+h} - \pred{y}{T+h}{T}$
\end{tabular}

\begin{align*}
\text{MAE} &= \text{mean}(|e_{T+h}|) \\[-0.2cm]
\text{MSE} &= \text{mean}(e_{T+h}^2) \qquad
&&\text{RMSE} &= \sqrt{\text{mean}(e_{T+h}^2)} \\[-0.1cm]
\text{MAPE} &= 100\text{mean}(|e_{T+h}|/ |y_{T+h}|)
\end{align*}\pause

  * MAE, MSE, RMSE are all scale dependent.
  * MAPE is scale independent but is only sensible if $y_t\gg 0$ for all $t$, and $y$ has a natural zero.

## Measures of forecast accuracy

\begin{block}{Mean Absolute Scaled Error}
$$
\text{MASE} = \text{mean}(|e_{T+h}|/Q)
$$
where $Q$ is a stable measure of the scale of the time series $\{y_t\}$.
\end{block}
Proposed by Hyndman and Koehler (IJF, 2006).

For non-seasonal time series,
$$
  Q = (T-1)^{-1}\sum_{t=2}^T |y_t-y_{t-1}|
$$
works well. Then MASE is equivalent to MAE relative to a naïve method.

\vspace*{10cm}

## Measures of forecast accuracy

\begin{block}{Mean Absolute Scaled Error}
$$
\text{MASE} = \text{mean}(|e_{T+h}|/Q)
$$
where $Q$ is a stable measure of the scale of the time series $\{y_t\}$.
\end{block}
Proposed by Hyndman and Koehler (IJF, 2006).

For seasonal time series,
$$
  Q = (T-m)^{-1}\sum_{t=m+1}^T |y_t-y_{t-m}|
$$
works well. Then MASE is equivalent to MAE relative to a seasonal naïve method.

\vspace*{10cm}

## Measures of forecast accuracy

\fontsize{10}{10}\sf

```{r beer-test-accuracy}
recent_production <- aus_production %>%
  filter(year(Quarter) >= 1992)
train <- recent_production %>% filter(year(Quarter) <= 2007)
beer_fit <- train %>%
  model(
    ets = ETS(Beer),
    arima = ARIMA(Beer)
  )
beer_fc <- forecast(beer_fit, h="4 years")
accuracy(beer_fc, aus_production)
```
